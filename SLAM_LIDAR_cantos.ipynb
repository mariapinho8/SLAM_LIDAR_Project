{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLAM com LIDAR: detecção de cantos e construção de mapa\n",
    "\n",
    "**Unidade Curricular:** Perception & Mapping  \n",
    "**Tema:** Implementação de um módulo simples de SLAM 2D com LIDAR (detecção de cantos)  \n",
    "\n",
    "Este *notebook* implementa a **Task 1** do enunciado:\n",
    "\n",
    "> Implementar um algoritmo que, a partir de varrimentos LIDAR 2D (121 feixes entre −60° e 60°),  \n",
    "> detecta cantos (convexos e côncavos), estima a trajectória do robô com odometria simples  \n",
    "> e projecta os cantos para o referencial do mundo.\n",
    "\n",
    "### Estrutura do notebook\n",
    "\n",
    "1. Leitura dos dados (`data.txt`)\n",
    "2. Modelo de odometria e trajectória 2D\n",
    "3. Processamento dos varrimentos LIDAR\n",
    "4. Detecção de cantos (convexos e côncavos) em cada varrimento\n",
    "5. Transformação dos cantos para o referencial do mundo\n",
    "6. Visualização da trajectória e do mapa de cantos\n",
    "7. Conclusões\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Para gráficos inline em Colab\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuração gráfica básica\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leitura dos dados\n",
    "\n",
    "O ficheiro `data.txt` contém, em cada linha:\n",
    "\n",
    "- Coluna 0: $\\Delta s_k$ — distância percorrida entre as amostras $k$ e $k+1$ (em metros);\n",
    "- Coluna 1: $\\Delta \\theta_k$ — variação de orientação do robô (em radianos, como será justificado);\n",
    "- Colunas 2 a 122: leituras LIDAR $r_{k,i}$, $i = 0, \\dots, 120$, correspondentes a 121 feixes entre -60° e +60°.  \n",
    "\n",
    "> **Nota:** Coloca o ficheiro `data.txt` no mesmo directório do *notebook* (em Colab, faz *Upload* do ficheiro).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(path=\"data.txt\"):\n",
    "    '''\n",
    "    Lê o ficheiro de dados.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta_s : np.ndarray, shape (N,)\n",
    "        Incrementos de distância [m].\n",
    "    delta_theta : np.ndarray, shape (N,)\n",
    "        Incrementos de orientação [rad].\n",
    "    ranges : np.ndarray, shape (N, 121)\n",
    "        Leituras LIDAR (raios) para cada varrimento.\n",
    "    '''\n",
    "    data = np.loadtxt(path)\n",
    "    delta_s = data[:, 0]\n",
    "    delta_theta = data[:, 1]\n",
    "    ranges = data[:, 2:]\n",
    "    return delta_s, delta_theta, ranges\n",
    "\n",
    "\n",
    "delta_s, delta_theta, ranges = load_data(\"data.txt\")\n",
    "N, num_beams = ranges.shape\n",
    "\n",
    "print(f\"Número de amostras (varrimentos): {N}\")\n",
    "print(f\"Número de feixes LIDAR por varrimento: {num_beams}\")\n",
    "print(f\"Δs: min={delta_s.min():.3f} m, max={delta_s.max():.3f} m\")\n",
    "print(f\"Δθ: min={delta_theta.min():.3f}, max={delta_theta.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Δθ em graus ou radianos?\n",
    "\n",
    "Para decidir se $\\Delta \\theta_k$ está em graus ou radianos, observamos o intervalo dos valores:\n",
    "\n",
    "- $ \\min(\\Delta \\theta_k) \\approx -0.19 $  \n",
    "- $ \\max(\\Delta \\theta_k) \\approx +0.19 $  \n",
    "\n",
    "Se estes valores estivessem em **graus**, a variação máxima de orientação por amostra seria inferior a 0.2°, o que é irrealista para um robô que percorre entre ~0.05 m e ~0.75 m por passo.  \n",
    "Se os interpretarmos como **radianos**, 0.19 rad $\\approx 10.9°$, o que é compatível com curvas suaves.\n",
    "\n",
    "Assim, consideramos:\n",
    "\\begin{equation}\n",
    "\\Delta \\theta_k \\; \\text{em radianos.}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Histograma de Δθ para visualização\n",
    "plt.figure()\n",
    "plt.hist(delta_theta, bins=40)\n",
    "plt.xlabel(r\"$\\Delta \\theta_k$ [rad]\")\n",
    "plt.ylabel(\"Contagem\")\n",
    "plt.title(\"Distribuição de $\\Delta \\\\theta_k$\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Angulos do LIDAR\n",
    "\n",
    "O LIDAR fornece 121 medições igualmente espaçadas entre -60° e +60°.  \n",
    "Geramos o vector de ângulos (em radianos) correspondente a cada feixe $i$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_i \\in [-60^\\circ, 60^\\circ], \\quad i = 0, \\dots, 120\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ângulos LIDAR: de -60° a 60° (inclusive) com passo de 1°\n",
    "angles_deg = np.linspace(-60.0, 60.0, num_beams)\n",
    "angles_rad = np.deg2rad(angles_deg)\n",
    "\n",
    "print(\"Primeiros 5 ângulos [deg]:\", angles_deg[:5])\n",
    "print(\"Primeiros 5 ângulos [rad]:\", angles_rad[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo de odometria e trajectória\n",
    "\n",
    "Assumimos o modelo cinemático simples dado no enunciado:\n",
    "\n",
    "\\begin{align}\n",
    "\\theta_{k+1} &= \\theta_k + \\Delta \\theta_k \\\\\n",
    "x_{k+1} &= x_k + \\Delta s_k \\cos(\\theta_k^\\*) \\\\\n",
    "y_{k+1} &= y_k + \\Delta s_k \\sin(\\theta_k^\\*)\n",
    "\\end{align}\n",
    "\n",
    "onde $\\theta_k^\\*$ é o ângulo usado para integrar o deslocamento linear.  \n",
    "Para aproximar melhor a trajectória contínua (modelo $dx/ds = \\cos\\theta$ e $dy/ds = \\sin\\theta$), usamos o **ângulo médio**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_k^\\* = \\theta_k + \\frac{1}{2}\\Delta \\theta_k\n",
    "\\end{equation}\n",
    "\n",
    "Isto corresponde a uma regra do ponto médio na integração em $s$, e é mais preciso do que usar apenas $\\theta_k$ ou apenas $\\theta_{k+1}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_odometry(delta_s, delta_theta, x0=0.0, y0=0.0, theta0=0.0):\n",
    "    '''\n",
    "    Integra odometria incremental para obter trajectória 2D.\n",
    "    \n",
    "    Usa ângulo intermédio theta_k + Δθ_k/2 para integrar Δs_k.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray, shape (N+1,)\n",
    "        Coordenadas x da trajectória.\n",
    "    y : np.ndarray, shape (N+1,)\n",
    "        Coordenadas y da trajectória.\n",
    "    theta : np.ndarray, shape (N+1,)\n",
    "        Orientação do robô (radianos).\n",
    "    '''\n",
    "    N = len(delta_s)\n",
    "    x = np.zeros(N + 1)\n",
    "    y = np.zeros(N + 1)\n",
    "    theta = np.zeros(N + 1)\n",
    "    \n",
    "    x[0], y[0], theta[0] = x0, y0, theta0\n",
    "    \n",
    "    for k in range(N):\n",
    "        theta_mid = theta[k] + 0.5 * delta_theta[k]\n",
    "        x[k+1] = x[k] + delta_s[k] * np.cos(theta_mid)\n",
    "        y[k+1] = y[k] + delta_s[k] * np.sin(theta_mid)\n",
    "        theta[k+1] = theta[k] + delta_theta[k]\n",
    "    \n",
    "    return x, y, theta\n",
    "\n",
    "\n",
    "x_traj, y_traj, theta_traj = compute_odometry(delta_s, delta_theta)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_traj, y_traj, \"-k\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Trajectória estimada por odometria\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversão LIDAR → coordenadas cartesianas (referencial do robô)\n",
    "\n",
    "Para cada varrimento, convertemos as medições $(r_i, \\alpha_i)$ em coordenadas cartesianas no **referencial do robô**:\n",
    "\n",
    "\\begin{align}\n",
    "x^R_i &= r_i \\cos \\alpha_i \\\\\n",
    "y^R_i &= r_i \\sin \\alpha_i\n",
    "\\end{align}\n",
    "\n",
    "onde o eixo $x^R$ aponta para a frente do robô e $y^R$ para a esquerda.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scan_to_cartesian(ranges_row, angles_rad):\n",
    "    '''\n",
    "    Converte um varrimento LIDAR (121 raios) para coordenadas cartesianas no referencial do robô.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ranges_row : np.ndarray, shape (num_beams,)\n",
    "        Raios medidos pelo LIDAR.\n",
    "    angles_rad : np.ndarray, shape (num_beams,)\n",
    "        Ângulos correspondentes (radianos).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    points : np.ndarray, shape (num_beams, 2)\n",
    "        Pontos (x^R, y^R) no referencial do robô.\n",
    "    '''\n",
    "    x_r = ranges_row * np.cos(angles_rad)\n",
    "    y_r = ranges_row * np.sin(angles_rad)\n",
    "    points = np.vstack((x_r, y_r)).T\n",
    "    return points\n",
    "\n",
    "\n",
    "# Exemplo com o primeiro varrimento\n",
    "points_example = scan_to_cartesian(ranges[0], angles_rad)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(points_example[:, 0], points_example[:, 1], \".\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(r\"$x^R$ [m] (frente do robô)\")\n",
    "plt.ylabel(r\"$y^R$ [m] (esquerda do robô)\")\n",
    "plt.title(\"Varrimento LIDAR no referencial do robô (amostra 0)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detecção de cantos (convexos e côncavos)\n",
    "\n",
    "Usamos a geometria local de 3 pontos consecutivos $P_{i-1}$, $P_i$, $P_{i+1}$:\n",
    "\n",
    "1. Calculamos os vectores\n",
    "   \\begin{align}\n",
    "   \\mathbf{v}_1 &= P_{i-1} - P_i \\\\\n",
    "   \\mathbf{v}_2 &= P_{i+1} - P_i\n",
    "   \\end{align}\n",
    "2. Calculamos o ângulo entre $\\mathbf{v}_1$ e $\\mathbf{v}_2$:\n",
    "   \\begin{equation}\n",
    "   \\cos \\phi_i = \\frac{\\mathbf{v}_1 \\cdot \\mathbf{v}_2}{\\|\\mathbf{v}_1\\| \\, \\|\\mathbf{v}_2\\|}\n",
    "   \\end{equation}\n",
    "3. Se $\\phi_i$ for suficientemente **agudo** (por exemplo $< 120^\\circ$), consideramos que existe um canto.\n",
    "\n",
    "Para distinguir **convexo** de **côncavo**, usamos a componente $z$ do produto vectorial 2D:  \n",
    "$\\mathbf{v}_1 \\times \\mathbf{v}_2 = v_{1x}v_{2y} - v_{1y}v_{2x}$.\n",
    "\n",
    "- Se $(\\mathbf{v}_1 \\times \\mathbf{v}_2)_z > 0$: definimos o canto como **convexo**;\n",
    "- Se $(\\mathbf{v}_1 \\times \\mathbf{v}_2)_z < 0$: definimos o canto como **côncavo**.\n",
    "\n",
    "Além disso, filtramos leituras absurdas (raios muito pequenos ou muito grandes) para reduzir cantos falsos devido a ruído.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def detect_corners_in_scan(points_xy, r_min=0.1, r_max=10.0, angle_threshold_deg=120.0):\n",
    "    '''\n",
    "    Detecta cantos (convexos / côncavos) num único varrimento no referencial do robô.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points_xy : np.ndarray, shape (num_beams, 2)\n",
    "        Pontos (x^R, y^R) do varrimento.\n",
    "    r_min, r_max : float\n",
    "        Limites mínimo e máximo de raio considerados válidos.\n",
    "    angle_threshold_deg : float\n",
    "        Ângulo máximo (em graus) para considerar que existe um canto (ex: 120°).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    corner_indices : list of int\n",
    "        Índices i dos pontos detectados como cantos.\n",
    "    corner_types : list of str\n",
    "        Tipo de canto em cada índice: \"convexo\" ou \"concavo\".\n",
    "    '''\n",
    "    num_points = points_xy.shape[0]\n",
    "    corner_indices = []\n",
    "    corner_types = []\n",
    "    \n",
    "    angle_threshold = np.deg2rad(angle_threshold_deg)\n",
    "    \n",
    "    # Cálculo dos raios para filtragem básica\n",
    "    radii = np.linalg.norm(points_xy, axis=1)\n",
    "    valid = (radii > r_min) & (radii < r_max)\n",
    "    \n",
    "    for i in range(1, num_points - 1):\n",
    "        if not (valid[i-1] and valid[i] and valid[i+1]):\n",
    "            continue\n",
    "        \n",
    "        p_prev = points_xy[i-1]\n",
    "        p_curr = points_xy[i]\n",
    "        p_next = points_xy[i+1]\n",
    "        \n",
    "        v1 = p_prev - p_curr\n",
    "        v2 = p_next - p_curr\n",
    "        \n",
    "        norm_v1 = np.linalg.norm(v1)\n",
    "        norm_v2 = np.linalg.norm(v2)\n",
    "        if norm_v1 < 1e-6 or norm_v2 < 1e-6:\n",
    "            continue\n",
    "        \n",
    "        # Ângulo entre v1 e v2\n",
    "        cos_phi = np.dot(v1, v2) / (norm_v1 * norm_v2)\n",
    "        # Limitar para [-1, 1] para evitar problemas numéricos\n",
    "        cos_phi = np.clip(cos_phi, -1.0, 1.0)\n",
    "        phi = np.arccos(cos_phi)\n",
    "        \n",
    "        if phi < angle_threshold:\n",
    "            # Produto vectorial 2D => componente z\n",
    "            cross_z = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "            if cross_z > 0:\n",
    "                c_type = \"convexo\"\n",
    "            else:\n",
    "                c_type = \"concavo\"\n",
    "            \n",
    "            corner_indices.append(i)\n",
    "            corner_types.append(c_type)\n",
    "    \n",
    "    return corner_indices, corner_types\n",
    "\n",
    "\n",
    "# Teste da função num varrimento\n",
    "test_scan = scan_to_cartesian(ranges[0], angles_rad)\n",
    "corner_idx, corner_types = detect_corners_in_scan(test_scan)\n",
    "\n",
    "print(f\"Número de cantos detectados no varrimento 0: {len(corner_idx)}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_scan[:, 0], test_scan[:, 1], \".\", label=\"pontos LIDAR\")\n",
    "if len(corner_idx) > 0:\n",
    "    corners = test_scan[corner_idx]\n",
    "    plt.scatter(corners[:, 0], corners[:, 1], s=60, facecolors=\"none\", edgecolors=\"r\", label=\"cantos\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(r\"$x^R$ [m]\")\n",
    "plt.ylabel(r\"$y^R$ [m]\")\n",
    "plt.title(\"Cantos detectados num varrimento (referencial do robô)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transformação dos cantos para o referencial do mundo\n",
    "\n",
    "Para cada varrimento $k$ e para cada canto detectado no referencial do robô $(x^R, y^R)$,  \n",
    "projectamos o ponto para o **referencial do mundo** usando a pose $(x_k, y_k, \\theta_k)$ estimada por odometria:\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}\n",
    "x^W \\\\[3pt]\n",
    "y^W\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_k \\\\[3pt]\n",
    "y_k\n",
    "\\end{bmatrix}\n",
    "+\n",
    "R(\\theta_k)\n",
    "\\begin{bmatrix}\n",
    "x^R \\\\[3pt]\n",
    "y^R\n",
    "\\end{bmatrix} \\\\[6pt]\n",
    "R(\\theta_k) &=\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta_k & -\\sin\\theta_k \\\\\n",
    "\\sin\\theta_k & \\cos\\theta_k\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Assumimos que cada varrimento LIDAR $k$ está associado à pose **após** aplicar o incremento $(\\Delta s_k, \\Delta \\theta_k)$, ou seja, à pose $(x_{k+1}, y_{k+1}, \\theta_{k+1})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_points_to_world(points_R, x_k, y_k, theta_k):\n",
    "    '''\n",
    "    Transforma pontos no referencial do robô para o referencial do mundo.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points_R : np.ndarray, shape (M, 2)\n",
    "        Pontos (x^R, y^R).\n",
    "    x_k, y_k : float\n",
    "        Posição do robô no mundo.\n",
    "    theta_k : float\n",
    "        Orientação do robô (rad).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    points_W : np.ndarray, shape (M, 2)\n",
    "        Pontos (x^W, y^W).\n",
    "    '''\n",
    "    c = np.cos(theta_k)\n",
    "    s = np.sin(theta_k)\n",
    "    R = np.array([[c, -s],\n",
    "                  [s,  c]])\n",
    "    return points_R @ R.T + np.array([x_k, y_k])\n",
    "\n",
    "\n",
    "# Loop global: detectar cantos em todos os varrimentos e transformá-los para o mundo\n",
    "world_corners = []  # lista de dicts com posição no robô, no mundo, tipo, varrimento e feixe\n",
    "\n",
    "for k in range(N):\n",
    "    # Pose usada para este varrimento: após aplicar o incremento k\n",
    "    x_k = x_traj[k+1]\n",
    "    y_k = y_traj[k+1]\n",
    "    theta_k = theta_traj[k+1]\n",
    "    \n",
    "    scan_points_R = scan_to_cartesian(ranges[k], angles_rad)\n",
    "    corner_idx, corner_types = detect_corners_in_scan(scan_points_R)\n",
    "    \n",
    "    if len(corner_idx) == 0:\n",
    "        continue\n",
    "    \n",
    "    corners_R = scan_points_R[corner_idx]\n",
    "    corners_W = transform_points_to_world(corners_R, x_k, y_k, theta_k)\n",
    "    \n",
    "    for idx, c_type, p_R, p_W in zip(corner_idx, corner_types, corners_R, corners_W):\n",
    "        world_corners.append({\n",
    "            \"scan_index\": k,\n",
    "            \"beam_index\": int(idx),\n",
    "            \"type\": c_type,\n",
    "            \"x_R\": float(p_R[0]),\n",
    "            \"y_R\": float(p_R[1]),\n",
    "            \"x_W\": float(p_W[0]),\n",
    "            \"y_W\": float(p_W[1]),\n",
    "        })\n",
    "\n",
    "print(f\"Número total de cantos detectados: {len(world_corners)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converte lista de cantos para arrays para facilitar a visualização\n",
    "corner_types = [c[\"type\"] for c in world_corners]\n",
    "xW = np.array([c[\"x_W\"] for c in world_corners])\n",
    "yW = np.array([c[\"y_W\"] for c in world_corners])\n",
    "\n",
    "is_convexo = np.array([t == \"convexo\" for t in corner_types])\n",
    "is_concavo = np.array([t == \"concavo\" for t in corner_types])\n",
    "\n",
    "print(f\"Cantos convexos: {is_convexo.sum()}\")\n",
    "print(f\"Cantos côncavos: {is_concavo.sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizações finais\n",
    "\n",
    "### 7.1. Trajectória do robô\n",
    "\n",
    "Primeiro representamos apenas a trajectória estimada por odometria.\n",
    "\n",
    "### 7.2. Mapa global de cantos\n",
    "\n",
    "Depois desenhamos:\n",
    "\n",
    "- Trajectória do robô;\n",
    "- Todos os cantos detectados no referencial do mundo,\n",
    "  - Cantos **convexos** numa cor,\n",
    "  - Cantos **côncavos** noutra cor.\n",
    "\n",
    "A opacidade dos pontos pode ser reduzida para evidenciar padrões globais.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 7.1 Trajectória\n",
    "plt.figure()\n",
    "plt.plot(x_traj, y_traj, \"-k\", label=\"trajetória\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Trajectória do robô (odometria)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7.2 Mapa de cantos\n",
    "plt.figure()\n",
    "plt.plot(x_traj, y_traj, \"-k\", linewidth=1.0, label=\"trajetória\")\n",
    "\n",
    "if is_convexo.any():\n",
    "    plt.scatter(xW[is_convexo], yW[is_convexo],\n",
    "                s=15, alpha=0.5, label=\"cantos convexos\")\n",
    "if is_concavo.any():\n",
    "    plt.scatter(xW[is_concavo], yW[is_concavo],\n",
    "                s=15, alpha=0.5, marker=\"x\", label=\"cantos côncavos\")\n",
    "\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(\"x^W [m]\")\n",
    "plt.ylabel(\"y^W [m]\")\n",
    "plt.title(\"Mapa global de cantos detectados (referencial do mundo)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusões\n",
    "\n",
    "Neste *notebook* implementámos:\n",
    "\n",
    "- Um modelo de **odometria incremental** para estimar a trajectória do robô a partir de $(\\Delta s_k, \\Delta \\theta_k)$;\n",
    "- A conversão das leituras **LIDAR polares para cartesianas** no referencial do robô;\n",
    "- Um método geométrico simples de **detecção de cantos (convexos e côncavos)** com base em 3 pontos consecutivos;\n",
    "- A **transformação dos cantos** do referencial do robô para o **referencial do mundo** usando a pose estimada por odometria;\n",
    "- A visualização conjunta da **trajetória** e do **mapa de cantos**, que constitui uma forma simples de SLAM baseado em marcos (landmarks).\n",
    "\n",
    "Este código é modular, podendo ser estendido para:\n",
    "- refinar os critérios de detecção de cantos;\n",
    "- agrupar cantos ao longo do tempo para estimar landmarks estáveis;\n",
    "- integrar um filtro de Kalman / EKF SLAM para fusão probabilística de odometria e observações.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Task 2 — EKF-SLAM online com cantos como marcos\n",
    "\n",
    "Nesta secção implementamos um **filtro de Kalman estendido (EKF)** para estimar em tempo real:\n",
    "\n",
    "- a pose do robô $(x, y, \\theta)$\n",
    "- as posições dos cantos (marcos) no mapa\n",
    "\n",
    "A cada instante $k$:\n",
    "\n",
    "1. Fazemos uma **previsão (prediction)** da pose com base na odometria $(\\Delta s_k, \\Delta \\theta_k)$;\n",
    "2. Detectamos cantos no varrimento LIDAR;\n",
    "3. Para cada canto detectado:\n",
    "   - Fazemos **data association**: verificamos se corresponde a um marco já conhecido;\n",
    "   - Se for **marco conhecido**, fazemos uma **actualização (update)** do EKF;\n",
    "   - Se for um **novo marco**, aumentamos o estado com as coordenadas deste novo canto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Modelo de estado e ruído\n",
    "\n",
    "### Estado\n",
    "\n",
    "O vector de estado é:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = \n",
    "\\begin{bmatrix}\n",
    "x \\\\ y \\\\ \\theta \\\\\n",
    "m_{1x} \\\\ m_{1y} \\\\\n",
    "\\vdots \\\\\n",
    "m_{Mx} \\\\ m_{My}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "onde $(x,y,\\theta)$ é a pose do robô e $(m_{jx}, m_{jy})$ são as coordenadas dos $M$ cantos (marcos) no **referencial do mundo**.\n",
    "\n",
    "### Matriz de covariância\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{P} \\in \\mathbb{R}^{(3+2M) \\times (3+2M)}\n",
    "\\end{equation}\n",
    "\n",
    "representa as incertezas e correlações entre pose e marcos.\n",
    "\n",
    "### Ruído de movimento (odometria)\n",
    "\n",
    "Assumimos um modelo de ruído simples, gaussiano, na odometria:\n",
    "\n",
    "- $\\sigma_\\text{trans}$ — desvio padrão em metros\n",
    "- $\\sigma_\\text{rot}$ — desvio padrão em radianos\n",
    "\n",
    "Destruidormente simples mas suficiente para este trabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hiperparâmetros do EKF (podem ser ajustados)\n",
    "SIGMA_TRANS = 0.05   # [m] ruído (1σ) de translação por passo\n",
    "SIGMA_ROT   = 0.02   # [rad] ruído (1σ) de rotação por passo\n",
    "\n",
    "# Ruído de medição (no referencial do robô, coordenadas x^R, y^R)\n",
    "SIGMA_MEAS_XR = 0.05  # [m]\n",
    "SIGMA_MEAS_YR = 0.05  # [m]\n",
    "\n",
    "R_meas = np.diag([SIGMA_MEAS_XR**2, SIGMA_MEAS_YR**2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Modelo de movimento (prediction)\n",
    "\n",
    "Usamos o mesmo modelo de odometria que antes, agora na forma de função de transição do estado:\n",
    "\n",
    "\\begin{align}\n",
    "\\theta_{k+1} &= \\theta_k + \\Delta \\theta_k \\\\\n",
    "\\theta_k^\\* &= \\theta_k + \\tfrac{1}{2}\\Delta \\theta_k \\\\\n",
    "x_{k+1} &= x_k + \\Delta s_k \\cos(\\theta_k^\\*) \\\\\n",
    "y_{k+1} &= y_k + \\Delta s_k \\sin(\\theta_k^\\*)\n",
    "\\end{align}\n",
    "\n",
    "Os marcos $m_j$ não se alteram na previsão (são estáticos).  \n",
    "A matriz Jacobiana $\\mathbf{F}_k = \\partial f / \\partial \\mathbf{x}$ será uma identidade com uma sub-matriz $3\\times 3$ modificada correspondente à pose.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ekf_predict(x, P, delta_s_k, delta_theta_k):\n",
    "    '''\n",
    "    Passo de previsão (prediction) do EKF para o movimento do robô.\n",
    "    \n",
    "    x : estado actual (dimensão 3 + 2M)\n",
    "    P : covariância actual\n",
    "    delta_s_k, delta_theta_k : incrementos de odometria\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_pred, P_pred, F\n",
    "    '''\n",
    "    n = x.shape[0]\n",
    "    # Extrair pose actual\n",
    "    xr, yr, theta = x[0], x[1], x[2]\n",
    "    \n",
    "    theta_mid = theta + 0.5 * delta_theta_k\n",
    "    xr_new = xr + delta_s_k * np.cos(theta_mid)\n",
    "    yr_new = yr + delta_s_k * np.sin(theta_mid)\n",
    "    theta_new = theta + delta_theta_k\n",
    "    \n",
    "    x_pred = x.copy()\n",
    "    x_pred[0] = xr_new\n",
    "    x_pred[1] = yr_new\n",
    "    x_pred[2] = theta_new\n",
    "    \n",
    "    # Jacobiana F = ∂f/∂x\n",
    "    F = np.eye(n)\n",
    "    dxdtheta = -delta_s_k * np.sin(theta_mid)\n",
    "    dydtheta =  delta_s_k * np.cos(theta_mid)\n",
    "    F[0, 2] = dxdtheta\n",
    "    F[1, 2] = dydtheta\n",
    "    \n",
    "    # Ruído de processo Q apenas na parte da pose\n",
    "    Q_pose = np.diag([SIGMA_TRANS**2, SIGMA_TRANS**2, SIGMA_ROT**2])\n",
    "    Q = np.zeros((n, n))\n",
    "    Q[0:3, 0:3] = Q_pose\n",
    "    \n",
    "    P_pred = F @ P @ F.T + Q\n",
    "    return x_pred, P_pred, F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Modelo de medição (measurement) e data association\n",
    "\n",
    "Para um marco $j$ com posição $(m_{jx}, m_{jy})$ no mundo, o modelo de medição exprime as suas coordenadas no **referencial do robô**:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{d} &=\n",
    "\\begin{bmatrix}\n",
    "m_{jx} - x \\\\ m_{jy} - y\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "x^R \\\\ y^R\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "R(\\theta)^\\top \\, \\mathbf{d}\n",
    "\\end{align}\n",
    "\n",
    "com\n",
    "\n",
    "\\begin{equation}\n",
    "R(\\theta)^\\top =\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta & \\sin\\theta \\\\\n",
    "-\\sin\\theta & \\cos\\theta\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "A função de medição é então $\\mathbf{z} = h(\\mathbf{x}) = [x^R, y^R]^T$.  \n",
    "Calculamos a Jacobiana $\\mathbf{H}_j$ de $h$ relativamente à pose e ao marco $j$ para construir a matriz de observação global.\n",
    "\n",
    "### Data association\n",
    "\n",
    "Para cada canto observado $z^{\\text{obs}}$:\n",
    "\n",
    "1. Para cada marco existente $j$, calculamos a previsão $z_j^{\\text{pred}}$ e a distância de Mahalanobis:\n",
    "   \\begin{equation}\n",
    "   d_j^2 = (\\mathbf{z}^{\\text{obs}} - \\mathbf{z}_j^{\\text{pred}})^\\top \\mathbf{S}_j^{-1} (\\mathbf{z}^{\\text{obs}} - \\mathbf{z}_j^{\\text{pred}})\n",
    "   \\end{equation}\n",
    "2. Escolhemos o marco com menor $d_j^2$;\n",
    "3. Se $d_{\\min}^2$ for inferior a um limiar (por exemplo baseado num valor $\\chi^2$ com 2 d.o.f.), consideramos que é um **marco conhecido**;\n",
    "4. Caso contrário, criamos um **novo marco** no estado.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def measurement_model_for_landmark(x, j):\n",
    "    '''\n",
    "    Calcula z_pred e Jacobiana H para o marco j.\n",
    "    \n",
    "    j : índice do marco (0, 1, 2, ...) não em termos de posição no vector, \n",
    "        mas o j-ésimo marco depois da pose.\n",
    "    '''\n",
    "    xr, yr, theta = x[0], x[1], x[2]\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    \n",
    "    # Índices no vector de estado do marco j\n",
    "    idx = 3 + 2*j\n",
    "    mx = x[idx]\n",
    "    my = x[idx+1]\n",
    "    \n",
    "    dx = mx - xr\n",
    "    dy = my - yr\n",
    "    \n",
    "    # Medição prevista no referencial do robô\n",
    "    x_r =  c*dx + s*dy\n",
    "    y_r = -s*dx + c*dy\n",
    "    z_pred = np.array([x_r, y_r])\n",
    "    \n",
    "    # Jacobiana H em relação ao estado completo\n",
    "    n = x.shape[0]\n",
    "    H = np.zeros((2, n))\n",
    "    \n",
    "    # Derivadas em relação a x, y, theta, mx, my\n",
    "    # z_xr =  c*dx + s*dy\n",
    "    # z_yr = -s*dx + c*dy\n",
    "    \n",
    "    # ∂z_xr/∂x = -c, ∂z_xr/∂y = -s, ∂z_xr/∂theta = -s*dx + c*dy\n",
    "    H[0, 0] = -c\n",
    "    H[0, 1] = -s\n",
    "    H[0, 2] = -s*dx + c*dy\n",
    "    # ∂z_xr/∂mx = c, ∂z_xr/∂my = s\n",
    "    H[0, idx]   = c\n",
    "    H[0, idx+1] = s\n",
    "    \n",
    "    # ∂z_yr/∂x =  s, ∂z_yr/∂y = -c, ∂z_yr/∂theta = -c*dx - s*dy\n",
    "    H[1, 0] =  s\n",
    "    H[1, 1] = -c\n",
    "    H[1, 2] = -c*dx - s*dy\n",
    "    # ∂z_yr/∂mx = -s, ∂z_yr/∂my = c\n",
    "    H[1, idx]   = -s\n",
    "    H[1, idx+1] =  c\n",
    "    \n",
    "    return z_pred, H\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ekf_update_for_measurement(x, P, z_obs, landmark_index):\n",
    "    '''\n",
    "    Atualização EKF para uma medição de um marco já existente.\n",
    "    \n",
    "    landmark_index : índice j do marco (0-based, em termos de \"marco j\")\n",
    "    '''\n",
    "    z_pred, H = measurement_model_for_landmark(x, landmark_index)\n",
    "    y = z_obs - z_pred  # inovação\n",
    "    \n",
    "    S = H @ P @ H.T + R_meas\n",
    "    K = P @ H.T @ np.linalg.inv(S)\n",
    "    \n",
    "    x_upd = x + K @ y\n",
    "    P_upd = (np.eye(P.shape[0]) - K @ H) @ P\n",
    "    return x_upd, P_upd\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ekf_add_new_landmark(x, P, z_obs):\n",
    "    '''\n",
    "    Cria um novo marco no estado a partir de uma medição z_obs = [x^R, y^R]\n",
    "    assumindo que a pose do robô está dada por x[0:3].\n",
    "    '''\n",
    "    xr, yr, theta = x[0], x[1], x[2]\n",
    "    c = np.cos(theta)\n",
    "    s = np.sin(theta)\n",
    "    \n",
    "    x_r, y_r = z_obs[0], z_obs[1]\n",
    "    \n",
    "    # Converter ponto no robô (x^R, y^R) para mundo (x^W, y^W)\n",
    "    # [x^W, y^W]^T = [x, y]^T + R(theta) * [x^R, y^R]^T\n",
    "    mx = xr + c*x_r - s*y_r\n",
    "    my = yr + s*x_r + c*y_r\n",
    "    \n",
    "    # Aumentar o vector de estado\n",
    "    x_new = np.concatenate([x, np.array([mx, my])])\n",
    "    \n",
    "    # Aumentar a covariância\n",
    "    n_old = P.shape[0]\n",
    "    P_new = np.zeros((n_old+2, n_old+2))\n",
    "    P_new[:n_old, :n_old] = P\n",
    "    \n",
    "    # Incerteza inicial do marco relativamente alta\n",
    "    sigma_m = 0.5  # [m]\n",
    "    P_new[n_old:, n_old:] = np.diag([sigma_m**2, sigma_m**2])\n",
    "    \n",
    "    return x_new, P_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Laço principal do EKF-SLAM\n",
    "\n",
    "Agora juntamos tudo:\n",
    "\n",
    "- Inicializamos o estado com apenas a pose $(0,0,0)$ e sem marcos;\n",
    "- Percorremos todas as amostras $k = 0, \\dots, N-1$;\n",
    "- Em cada passo:\n",
    "  1. `ekf_predict` com a odometria $(\\Delta s_k, \\Delta \\theta_k)$;\n",
    "  2. Convertemos o varrimento LIDAR para o referencial do robô;\n",
    "  3. Detectamos cantos com `detect_corners_in_scan`;\n",
    "  4. Para cada canto detectado:\n",
    "     - Fazemos data association com base na distância de Mahalanobis;\n",
    "     - Actualizamos o estado ou adicionamos um novo marco.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Limiar para a distância de Mahalanobis (2 d.o.f.)\n",
    "# Valores de referência: chi2(0.99, 2) ≈ 9.21, chi2(0.95, 2) ≈ 5.99\n",
    "MAHALANOBIS_THRESHOLD = 9.21\n",
    "\n",
    "# Estado inicial: apenas pose\n",
    "x_ekf = np.array([0.0, 0.0, 0.0])\n",
    "P_ekf = np.diag([1e-6, 1e-6, 1e-6])  # praticamente certeza absoluta no início\n",
    "\n",
    "# Para armazenamento da trajectória estimada pelo EKF\n",
    "ekf_poses = []  # lista de (x, y, theta)\n",
    "num_landmarks_over_time = []\n",
    "\n",
    "for k in range(N):\n",
    "    # 1) Prediction\n",
    "    x_ekf, P_ekf, F_k = ekf_predict(x_ekf, P_ekf, delta_s[k], delta_theta[k])\n",
    "    \n",
    "    # Guardar pose após previsão (antes de medições)\n",
    "    ekf_poses.append(x_ekf[0:3].copy())\n",
    "    num_landmarks = (x_ekf.shape[0] - 3) // 2\n",
    "    num_landmarks_over_time.append(num_landmarks)\n",
    "    \n",
    "    # 2) Processar varrimento e detectar cantos\n",
    "    scan_points_R = scan_to_cartesian(ranges[k], angles_rad)\n",
    "    corner_idx, corner_types_k = detect_corners_in_scan(scan_points_R)\n",
    "    \n",
    "    if len(corner_idx) == 0:\n",
    "        continue\n",
    "    \n",
    "    for idx in corner_idx:\n",
    "        z_obs = scan_points_R[idx]  # [x^R, y^R]\n",
    "        \n",
    "        # Data association: procurar marco mais provável\n",
    "        num_landmarks = (x_ekf.shape[0] - 3) // 2\n",
    "        if num_landmarks == 0:\n",
    "            # Primeiro marco: adicionar directamente\n",
    "            x_ekf, P_ekf = ekf_add_new_landmark(x_ekf, P_ekf, z_obs)\n",
    "            continue\n",
    "        \n",
    "        best_j = None\n",
    "        best_d2 = None\n",
    "        \n",
    "        for j in range(num_landmarks):\n",
    "            z_pred, H = measurement_model_for_landmark(x_ekf, j)\n",
    "            y = z_obs - z_pred\n",
    "            S = H @ P_ekf @ H.T + R_meas\n",
    "            try:\n",
    "                S_inv = np.linalg.inv(S)\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue\n",
    "            d2 = float(y.T @ S_inv @ y)\n",
    "            if best_d2 is None or d2 < best_d2:\n",
    "                best_d2 = d2\n",
    "                best_j = j\n",
    "        \n",
    "        # Verificar se melhor correspondência é suficientemente boa\n",
    "        if best_d2 is not None and best_d2 < MAHALANOBIS_THRESHOLD:\n",
    "            # Marco conhecido -> update EKF\n",
    "            x_ekf, P_ekf = ekf_update_for_measurement(x_ekf, P_ekf, z_obs, best_j)\n",
    "        else:\n",
    "            # Novo marco\n",
    "            x_ekf, P_ekf = ekf_add_new_landmark(x_ekf, P_ekf, z_obs)\n",
    "\n",
    "# Converter trajectória EKF para arrays\n",
    "ekf_poses = np.array(ekf_poses)  # shape (N, 3)\n",
    "num_landmarks_over_time = np.array(num_landmarks_over_time)\n",
    "\n",
    "print(\"Dimensão final do estado EKF:\", x_ekf.shape[0])\n",
    "print(\"Número final de marcos:\", (x_ekf.shape[0] - 3) // 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Resultados do EKF-SLAM\n",
    "\n",
    "Vamos comparar a trajectória baseada apenas em odometria com a trajectória estimada pelo EKF-SLAM, e visualizar a posição final dos marcos (cantos) no mapa.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trajectória por odometria (já tínhamos x_traj, y_traj)\n",
    "x_odo = x_traj[1:1+N]\n",
    "y_odo = y_traj[1:1+N]\n",
    "\n",
    "# Trajectória EKF (x, y)\n",
    "x_ekf_traj = ekf_poses[:, 0]\n",
    "y_ekf_traj = ekf_poses[:, 1]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_odo, y_odo, \"--\", label=\"odometria\")\n",
    "plt.plot(x_ekf_traj, y_ekf_traj, \"-\", label=\"EKF-SLAM\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Comparação de trajectórias: odometria vs EKF-SLAM\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Mapa de marcos estimados pelo EKF\n",
    "num_landmarks_final = (x_ekf.shape[0] - 3) // 2\n",
    "mx_list = []\n",
    "my_list = []\n",
    "for j in range(num_landmarks_final):\n",
    "    idx = 3 + 2*j\n",
    "    mx_list.append(x_ekf[idx])\n",
    "    my_list.append(x_ekf[idx+1])\n",
    "mx_list = np.array(mx_list)\n",
    "my_list = np.array(my_list)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_ekf_traj, y_ekf_traj, \"-\", label=\"trajetória EKF\")\n",
    "plt.scatter(mx_list, my_list, marker=\"*\", s=30, label=\"marcos (cantos)\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(\"x^W [m]\")\n",
    "plt.ylabel(\"y^W [m]\")\n",
    "plt.title(\"Mapa de cantos estimado pelo EKF-SLAM\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evolução do número de marcos\n",
    "plt.figure()\n",
    "plt.plot(num_landmarks_over_time)\n",
    "plt.xlabel(\"tempo (índice k)\")\n",
    "plt.ylabel(\"número de marcos\")\n",
    "plt.title(\"Evolução do número de marcos no EKF-SLAM\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Task 3 — Evolução da pose e do mapa, e noção de smoothing\n",
    "\n",
    "A Task 3 pede:\n",
    "\n",
    "> *\"Based on all the measurements, estimate the evolution of the pose of the robot and of the map of the environment.  \n",
    "> Suggestion: Look for information about smoothing in the literature.\"*\n",
    "\n",
    "Neste *notebook* já temos:\n",
    "\n",
    "- A **evolução da pose** ao longo do tempo, estimada pelo EKF-SLAM (`ekf_poses`);\n",
    "- O **mapa dos cantos** (marcos) estimado a partir de todas as medições disponíveis até cada instante;\n",
    "- A forma clássica de **filtro** (filtering): em cada instante usamos apenas as medições até esse instante.\n",
    "\n",
    "Nesta secção:\n",
    "\n",
    "1. Visualizamos explicitamente a evolução da pose e do mapa ao longo do tempo;\n",
    "2. Discutimos a noção de **smoothing** em SLAM e como se poderia estender este trabalho para implementar um *smoother* (por exemplo, RTS smoother ou Graph-SLAM).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evolução da pose (x, y, theta) ao longo do tempo\n",
    "t = np.arange(N)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(t, ekf_poses[:,0])\n",
    "plt.ylabel(\"x [m]\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(t, ekf_poses[:,1])\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(t, ekf_poses[:,2])\n",
    "plt.ylabel(r\"$\\theta$ [rad]\")\n",
    "plt.xlabel(\"índice de tempo k\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle(\"Evolução da pose do robô (EKF-SLAM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. Smoothing vs Filtering\n",
    "\n",
    "No EKF-SLAM que implementámos até agora fazemos **filtering**:\n",
    "\n",
    "- A estimativa em $k$ usa apenas medições até $k$;\n",
    "- Quando surgem medições futuras $(k' > k)$, **não** corrigimos retroactivamente as estimativas passadas.\n",
    "\n",
    "Em **smoothing**, em vez de estimar apenas $\\mathbf{x}_k$ dado o passado, estimamos **toda a trajectória** e mapa:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\mathbf{x}_{0:T}, \\mathcal{M} \\mid \\mathcal{Z}_{0:T}, \\mathcal{U}_{0:T})\n",
    "\\end{equation}\n",
    "\n",
    "usando **todas** as medições $\\mathcal{Z}_{0:T}$ e comandos/odometria $\\mathcal{U}_{0:T}$.\n",
    "\n",
    "### Exemplos de técnicas de smoothing\n",
    "\n",
    "- **Rauch–Tung–Striebel (RTS) smoother**:  \n",
    "  - Faz-se uma passada forward com EKF (guardar $x_k^{\\text{pred}}, x_k^{\\text{filt}}, P_k^{\\text{pred}}, P_k^{\\text{filt}}, F_k$);  \n",
    "  - Depois uma passada backward com as equações de smoothing:\n",
    "    \\begin{align}\n",
    "    \\mathbf{C}_k &= \\mathbf{P}_k^{\\text{filt}} F_k^\\top \\left(\\mathbf{P}_{k+1}^{\\text{pred}}\\right)^{-1} \\\\\n",
    "    \\mathbf{x}_k^{\\text{smooth}} &= \\mathbf{x}_k^{\\text{filt}} + \\mathbf{C}_k \\left(\\mathbf{x}_{k+1}^{\\text{smooth}} - \\mathbf{x}_{k+1}^{\\text{pred}}\\right)\n",
    "    \\end{align}\n",
    "- **Graph-SLAM / bundle adjustment**:  \n",
    "  - Modela-se toda a trajectória e mapa como um problema de **optimização não linear** (grafo de factores);  \n",
    "  - Minimiza-se a soma dos erros de todas as medições (odometria + observações LIDAR) sobre todas as poses e marcos.\n",
    "\n",
    "### Extensão possível (trabalho futuro)\n",
    "\n",
    "Para manter o código claro e dentro do contexto da UC, não implementamos aqui um smoother completo, mas seria possível:\n",
    "\n",
    "1. Guardar, na fase de EKF-SLAM forward, as matrizes $F_k$, $P_k^{\\text{pred}}$, $P_k^{\\text{filt}}$ e os estados filtrados;\n",
    "2. Implementar um **RTS smoother** para obter uma trajectória suavizada $(x_k^{\\text{smooth}}, y_k^{\\text{smooth}}, \\theta_k^{\\text{smooth}})$;\n",
    "3. Comparar graficamente trajectória por odometria, por EKF filtrado e por EKF suavizado.\n",
    "\n",
    "Esta discussão mostra a diferença entre *filtering* (o que implementámos) e *smoothing* (extensão natural discutida na literatura de SLAM).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SLAM_LIDAR_cantos.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}